{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_time_series.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMp7wf9sp9TsWbvv3qE7WE/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"hEjpjwASO9o7","executionInfo":{"status":"ok","timestamp":1661636278705,"user_tz":420,"elapsed":6972,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"52b4f2bb-0fd2-4023-d181-08787c30bfcd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["\"\\n# load dataset\\nseries = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\\n\\n# transform data to be stationary\\nraw_values = series.values\\ndiff_values = difference(raw_values, 1)\\n\\n# transform data to be supervised learning\\nsupervised = timeseries_to_supervised(diff_values, 1)\\nsupervised_values = supervised.values\\n\\n# split data into train and test-sets\\ntrain, test = supervised_values[0:-12], supervised_values[-12:]\\n\\n# transform the scale of the data\\nscaler, train_scaled, test_scaled = scale(train, test)\\n\\n# fit the model\\nlstm_model = fit_lstm(train_scaled, 1, 3000, 4)\\n# forecast the entire training dataset to build up state for forecasting\\ntrain_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\\nlstm_model.predict(train_reshaped, batch_size=1)\\n\\n# walk-forward validation on the test data\\npredictions = list()\\nfor i in range(len(test_scaled)):\\n\\t# make one-step forecast\\n\\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\\n\\tyhat = forecast_lstm(lstm_model, 1, X)\\n\\t# invert scaling\\n\\tyhat = invert_scale(scaler, X, yhat)\\n\\t# invert differencing\\n\\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\\n\\t# store forecast\\n\\tpredictions.append(yhat)\\n\\texpected = raw_values[len(train) + i + 1]\\n\\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\\n\\n# report performance\\nrmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\\nprint('Test RMSE: %.3f' % rmse)\\n# line plot of observed vs predicted\\npyplot.plot(raw_values[-12:])\\npyplot.plot(predictions)\\npyplot.show()\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# reference:\n","# https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n","\n","from pandas import DataFrame\n","from pandas import Series\n","from pandas import concat\n","from pandas import read_csv\n","from pandas import datetime\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from math import sqrt\n","from matplotlib import pyplot\n","import numpy\n","\n","# date-time parsing function for loading the dataset\n","def parser(x):\n","\treturn datetime.strptime('190'+x, '%Y-%m')\n","\n","# frame a sequence as a supervised learning problem\n","def timeseries_to_supervised(data, lag=1):\n","\tdf = DataFrame(data)\n","\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n","\tcolumns.append(df)\n","\tdf = concat(columns, axis=1)\n","\tdf.fillna(0, inplace=True)\n","\treturn df\n","\n","# create a differenced series\n","def difference(dataset, interval=1):\n","\tdiff = list()\n","\tfor i in range(interval, len(dataset)):\n","\t\tvalue = dataset[i] - dataset[i - interval]\n","\t\tdiff.append(value)\n","\treturn Series(diff)\n","\n","# invert differenced value\n","def inverse_difference(history, yhat, interval=1):\n","\treturn yhat + history[-interval]\n","\n","# scale train and test data to [-1, 1]\n","def scale(train, test):\n","\t# fit scaler\n","\tscaler = MinMaxScaler(feature_range=(-1, 1))\n","\tscaler = scaler.fit(train)\n","\t# transform train\n","\ttrain = train.reshape(train.shape[0], train.shape[1])\n","\ttrain_scaled = scaler.transform(train)\n","\t# transform test\n","\ttest = test.reshape(test.shape[0], test.shape[1])\n","\ttest_scaled = scaler.transform(test)\n","\treturn scaler, train_scaled, test_scaled\n","\n","# inverse scaling for a forecasted value\n","def invert_scale(scaler, X, value):\n","\tnew_row = [x for x in X] + [value]\n","\tarray = numpy.array(new_row)\n","\tarray = array.reshape(1, len(array))\n","\tinverted = scaler.inverse_transform(array)\n","\treturn inverted[0, -1]\n","\n","# fit an LSTM network to training data\n","def fit_lstm(train, batch_size, nb_epoch, units):\n","\tX, y = train[:, 0:-1], train[:, -1]\n","\tX = X.reshape(X.shape[0], 1, X.shape[1])\n","\tmodel = Sequential()\n","\tmodel.add(LSTM(units, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n","\tmodel.add(Dense(1))\n","\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n","\tfor i in range(nb_epoch):\n","\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n","\t\tmodel.reset_states()\n","\treturn model\n","\n","# make a one-step forecast\n","def forecast_lstm(model, batch_size, X):\n","\tX = X.reshape(1, 1, len(X))\n","\tyhat = model.predict(X, batch_size=batch_size)\n","\treturn yhat[0,0]\n","\n","'''\n","# load dataset\n","series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n","\n","# transform data to be stationary\n","raw_values = series.values\n","diff_values = difference(raw_values, 1)\n","\n","# transform data to be supervised learning\n","supervised = timeseries_to_supervised(diff_values, 1)\n","supervised_values = supervised.values\n","\n","# split data into train and test-sets\n","train, test = supervised_values[0:-12], supervised_values[-12:]\n","\n","# transform the scale of the data\n","scaler, train_scaled, test_scaled = scale(train, test)\n","\n","# fit the model\n","lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n","# forecast the entire training dataset to build up state for forecasting\n","train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n","lstm_model.predict(train_reshaped, batch_size=1)\n","\n","# walk-forward validation on the test data\n","predictions = list()\n","for i in range(len(test_scaled)):\n","\t# make one-step forecast\n","\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n","\tyhat = forecast_lstm(lstm_model, 1, X)\n","\t# invert scaling\n","\tyhat = invert_scale(scaler, X, yhat)\n","\t# invert differencing\n","\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n","\t# store forecast\n","\tpredictions.append(yhat)\n","\texpected = raw_values[len(train) + i + 1]\n","\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n","\n","# report performance\n","rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n","print('Test RMSE: %.3f' % rmse)\n","# line plot of observed vs predicted\n","pyplot.plot(raw_values[-12:])\n","pyplot.plot(predictions)\n","pyplot.show()\n","'''\n"]},{"cell_type":"code","source":["# enable access to my google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7O8JGcwsP6pI","executionInfo":{"status":"ok","timestamp":1661636479095,"user_tz":420,"elapsed":19525,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"8806f4a3-4041-4aec-aa14-deeb6eafdc79"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"dhoqqr_YQPx4","executionInfo":{"status":"ok","timestamp":1661636514406,"user_tz":420,"elapsed":247,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"1e7a632b-b27f-458b-d537-407f460815a1"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# load dataset\n","series = read_csv('/content/gdrive/My Drive/Colab/shampoo.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)"],"metadata":{"id":"Vxb4HbErPlyr","executionInfo":{"status":"ok","timestamp":1661636598253,"user_tz":420,"elapsed":520,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# transform data to be stationary\n","raw_values = series.values\n","diff_values = difference(raw_values, interval=1)\n","print(raw_values)\n","print(diff_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OvfeGTLIQmUf","executionInfo":{"status":"ok","timestamp":1661636995305,"user_tz":420,"elapsed":142,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"b86cae9d-4086-42c3-aca3-63b6b362d324"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[266.  145.9 183.1 119.3 180.3 168.5 231.8 224.5 192.8 122.9 336.5 185.9\n"," 194.3 149.5 210.1 273.3 191.4 287.  226.  303.6 289.9 421.6 264.5 342.3\n"," 339.7 440.4 315.9 439.3 401.3 437.4 575.5 407.6 682.  475.3 581.3 646.9]\n","0    -120.1\n","1      37.2\n","2     -63.8\n","3      61.0\n","4     -11.8\n","5      63.3\n","6      -7.3\n","7     -31.7\n","8     -69.9\n","9     213.6\n","10   -150.6\n","11      8.4\n","12    -44.8\n","13     60.6\n","14     63.2\n","15    -81.9\n","16     95.6\n","17    -61.0\n","18     77.6\n","19    -13.7\n","20    131.7\n","21   -157.1\n","22     77.8\n","23     -2.6\n","24    100.7\n","25   -124.5\n","26    123.4\n","27    -38.0\n","28     36.1\n","29    138.1\n","30   -167.9\n","31    274.4\n","32   -206.7\n","33    106.0\n","34     65.6\n","dtype: float64\n"]}]},{"cell_type":"code","source":["diff_values.shift(1)\n","# there is a NaN, so in timeseries_to_supervised, fillna(0) is done to replace NaN with 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Lp9l7TdUFEp","executionInfo":{"status":"ok","timestamp":1661637529727,"user_tz":420,"elapsed":148,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"0b3cc737-91aa-48f2-97e9-792c16096f7f"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       NaN\n","1    -120.1\n","2      37.2\n","3     -63.8\n","4      61.0\n","5     -11.8\n","6      63.3\n","7      -7.3\n","8     -31.7\n","9     -69.9\n","10    213.6\n","11   -150.6\n","12      8.4\n","13    -44.8\n","14     60.6\n","15     63.2\n","16    -81.9\n","17     95.6\n","18    -61.0\n","19     77.6\n","20    -13.7\n","21    131.7\n","22   -157.1\n","23     77.8\n","24     -2.6\n","25    100.7\n","26   -124.5\n","27    123.4\n","28    -38.0\n","29     36.1\n","30    138.1\n","31   -167.9\n","32    274.4\n","33   -206.7\n","34    106.0\n","dtype: float64"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# transform data to be supervised learning\n","supervised = timeseries_to_supervised(diff_values, lag=1)\n","supervised_values = supervised.values\n","\n","# split data into train and test-sets\n","train, test = supervised_values[0:-12], supervised_values[-12:]\n","\n","# transform the scale of the data\n","scaler, train_scaled, test_scaled = scale(train, test)"],"metadata":{"id":"rCejBL8NSNQs","executionInfo":{"status":"ok","timestamp":1661637504709,"user_tz":420,"elapsed":142,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["train_scaled"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ftR6z0kTXbK","executionInfo":{"status":"ok","timestamp":1661637506650,"user_tz":420,"elapsed":160,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"90aee09d-e7b6-4e4a-93c9-c951c4867445"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.15241435, -0.80037766],\n","       [-0.80037766,  0.04828702],\n","       [ 0.04828702, -0.496628  ],\n","       [-0.496628  ,  0.17669274],\n","       [ 0.17669274, -0.21607769],\n","       [-0.21607769,  0.1891017 ],\n","       [ 0.1891017 , -0.1917993 ],\n","       [-0.1917993 , -0.32344214],\n","       [-0.32344214, -0.52953871],\n","       [-0.52953871,  1.        ],\n","       [ 1.        , -0.96493121],\n","       [-0.96493121, -0.10709469],\n","       [-0.10709469, -0.39411923],\n","       [-0.39411923,  0.17453466],\n","       [ 0.17453466,  0.18856218],\n","       [ 0.18856218, -0.59428109],\n","       [-0.59428109,  0.3633666 ],\n","       [ 0.3633666 , -0.48152145],\n","       [-0.48152145,  0.26625303],\n","       [ 0.26625303, -0.22632857],\n","       [-0.22632857,  0.55813326],\n","       [ 0.55813326, -1.        ],\n","       [-1.        ,  0.26733207]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["'''\n","# code for fit_lstm:\n","def fit_lstm(train, batch_size, nb_epoch, units):\n","\tX, y = train[:, 0:-1], train[:, -1]\n","\tX = X.reshape(X.shape[0], 1, X.shape[1])\n","\tmodel = Sequential()\n","\tmodel.add(LSTM(units, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n","\tmodel.add(Dense(1))\n","\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n","\tfor i in range(nb_epoch):\n","\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n","\t\tmodel.reset_states()\n","\treturn model\n","'''\n","\n","# fit the model\n","lstm_model = fit_lstm(train_scaled, batch_size=1, nb_epoch=3000, units=4)\n","# forecast the entire training dataset to build up state for forecasting\n","train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n","lstm_model.predict(train_reshaped, batch_size=1)"],"metadata":{"id":"0pSyQ81KVncu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X, y = train_scaled[:, 0:-1], train_scaled[:, -1]"],"metadata":{"id":"vZGB2uriW1AW","executionInfo":{"status":"ok","timestamp":1661638647761,"user_tz":420,"elapsed":170,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["X = X.reshape(X.shape[0], 1, X.shape[1])\n","X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkNZYzM6YaeD","executionInfo":{"status":"ok","timestamp":1661638725212,"user_tz":420,"elapsed":179,"user":{"displayName":"許瀚元","userId":"06242862820898425544"}},"outputId":"71282e10-0bcd-420c-f84e-ed737854ef3b"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(23, 1, 1)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["I don't like how machinelearningmastery did this ..."],"metadata":{"id":"fOSKJp4knqFO"}}]}